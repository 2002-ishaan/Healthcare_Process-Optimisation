{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5: Machine Learning for ED Triage Optimization\n",
    "## Production-Grade Predictive Analytics\n",
    "\n",
    "---\n",
    "\n",
    "### Strategic Question: Which Prediction Target(s) Should We Optimize?\n",
    "\n",
    "The project allows: \"Probability of Admission\" **OR** \"Probability of LWBS\" **OR** \"Remaining Time to PIA\"\n",
    "\n",
    "**Our Analysis:**\n",
    "\n",
    "| Target | Operational Value | Data Quality | Actionability | Recommendation |\n",
    "|--------|-------------------|--------------|---------------|----------------|\n",
    "| **Admission** | HIGH â€” enables bed planning, early consults | Good signal (14% rate) | Immediate action possible | âœ… PRIMARY |\n",
    "| **LWBS** | HIGH â€” prevents patient safety issues | Weak signal (1.5% rate) | Proactive monitoring | âœ… SECONDARY |\n",
    "| **PIA Time** | MEDIUM â€” patient communication | Weak signal (RÂ²<0.20) | Limited actionability | âš ï¸ OPTIONAL |\n",
    "\n",
    "**Decision: Build TWO optimized models (Admission + LWBS)**\n",
    "\n",
    "**Rationale:**\n",
    "1. Both targets drive different but complementary decisions\n",
    "2. They can run in parallel with minimal latency\n",
    "3. Combined, they give Triage Lead a complete risk picture\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ XGBoost available\n",
      "âœ“ LightGBM available\n",
      "\n",
      "âœ“ All core imports successful\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML Core\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, StratifiedKFold, \n",
    "    RandomizedSearchCV, GridSearchCV\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Models to Compare\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Try to import XGBoost and LightGBM (may need installation)\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "    print(\"âœ“ XGBoost available\")\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"âš  XGBoost not available â€” using GradientBoosting instead\")\n",
    "\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "    LIGHTGBM_AVAILABLE = True\n",
    "    print(\"âœ“ LightGBM available\")\n",
    "except ImportError:\n",
    "    LIGHTGBM_AVAILABLE = False\n",
    "    print(\"âš  LightGBM not available â€” using GradientBoosting instead\")\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    confusion_matrix, classification_report, brier_score_loss,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "# For calibration\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "print(\"\\nâœ“ All core imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NTH-ED DATA LOADING PIPELINE\n",
      "============================================================\n",
      "ðŸ“¥ Loading event log...\n",
      "   âœ“ Loaded 90,965 events\n",
      "   âœ“ 16,011 unique patient visits\n",
      "   âœ“ Columns: ['visit_id', 'patient_id', 'initial_zone', 'age', 'month', 'day', 'gender', 'triage_code', 'triage_desc', 'disposition_code', 'disposition_desc', 'consult_desc', 'cdu_flag', 'consult_req_flag', 'consult_arrival_flag', 'event', 'timestamp']\n",
      "\n",
      "â° Parsing timestamps...\n",
      "   âœ“ All timestamps parsed successfully\n",
      "   âœ“ Date range: 2021-03-31 23:59:00 to 2021-06-01 17:16:00\n",
      "\n",
      "ðŸ”§ Handling missing data...\n",
      "   â€¢ initial_zone: 1,950 missing (2.1%)\n",
      "   â€¢ triage_code: 3 missing (0.0%)\n",
      "   â€¢ consult_desc: 69,698 missing (76.6%)\n",
      "   â€¢ age: 0 missing (0.0%)\n",
      "   âœ“ Missing zones filled with 'Unknown'\n",
      "   âœ“ Missing consults marked as 'No Consult'\n",
      "\n",
      "ðŸ“‹ Standardizing columns for process mining...\n",
      "   âœ“ Created process mining columns: case_id, activity, resource\n",
      "   âœ“ Created outcome flags: is_admitted, is_lwbs\n",
      "\n",
      "ðŸ”€ Sorting events with logical ordering...\n",
      "   âœ“ Events sorted by case_id â†’ timestamp â†’ logical order\n",
      "\n",
      "ðŸ“Š Creating visit-level summary...\n",
      "   âš  pia_minutes: 106 negative values set to NaN\n",
      "   âš  triage_to_reg_minutes: 8 negative values set to NaN\n",
      "   âš  los_minutes: 2 negative values set to NaN\n",
      "   âœ“ Created 16,011 visit summaries\n",
      "   âœ“ Key wait times calculated: PIA, Triage-to-Reg, Consult Wait, LOS\n",
      "   âœ“ Flags created: is_ambulance, has_consult, is_admitted, is_lwbs\n",
      "\n",
      "============================================================\n",
      "DATA PREPARATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "ðŸ“ˆ EVENT LOG SUMMARY:\n",
      "   â€¢ Total events: 90,965\n",
      "   â€¢ Unique visits: 16,011\n",
      "   â€¢ Event types: 9\n",
      "   â€¢ Zones: 10\n",
      "\n",
      "ðŸ“Š VISIT SUMMARY:\n",
      "   â€¢ Total visits: 16,011\n",
      "   â€¢ Admission rate: 13.9%\n",
      "   â€¢ LWBS rate: 1.5%\n",
      "   â€¢ Ambulance arrivals: 19.5%\n",
      "   â€¢ Median PIA time: 34 minutes\n",
      "   â€¢ Median LOS: 191 minutes\n",
      "\n",
      "============================================================\n",
      "SAMPLE OUTPUT\n",
      "============================================================\n",
      "\n",
      "ðŸ” Sample Event Log (first 10 rows):\n",
      "   case_id           activity           timestamp resource triage_level\n",
      "0  5240985          Discharge 2021-04-28 00:00:00  Unknown  2-EMERGENCY\n",
      "1  5240985            Left ED 2021-04-28 00:00:00  Unknown  2-EMERGENCY\n",
      "2  5240985             Triage 2021-04-28 01:30:00  Unknown  2-EMERGENCY\n",
      "3  5240985       Registration 2021-04-28 01:45:00  Unknown  2-EMERGENCY\n",
      "4  7214779             Triage 2021-05-21 11:17:00       YZ     3-URGENT\n",
      "5  7214779       Registration 2021-05-21 11:27:00       YZ     3-URGENT\n",
      "6  7214779          Discharge 2021-05-21 12:09:00       YZ     3-URGENT\n",
      "7  7214779            Left ED 2021-05-21 12:09:00       YZ     3-URGENT\n",
      "8  7268604  Ambulance Arrival 2021-04-11 00:00:00    Resus  2-EMERGENCY\n",
      "9  7268604             Triage 2021-04-11 13:04:00    Resus  2-EMERGENCY\n",
      "\n",
      "ðŸ” Sample Visit Summary (first 5 rows):\n",
      "   case_id initial_zone triage_level  pia_minutes  los_minutes  is_admitted  \\\n",
      "0  5240985      Unknown  2-EMERGENCY          NaN          NaN            0   \n",
      "1  7214779           YZ     3-URGENT          NaN         52.0            0   \n",
      "2  7268604        Resus  2-EMERGENCY        492.0        853.0            1   \n",
      "3  7384128           SA     3-URGENT        133.0       1100.0            1   \n",
      "4  7384129           YZ     3-URGENT         40.0         97.0            0   \n",
      "\n",
      "   is_lwbs  \n",
      "0        1  \n",
      "1        1  \n",
      "2        0  \n",
      "3        0  \n",
      "4        0  \n",
      "\n",
      "ðŸ“Š Zone Summary:\n",
      "              Visit Count  Median PIA (min)  Median LOS (min)  Admission Rate  \\\n",
      "initial_zone                                                                    \n",
      "YZ                   4232              51.0             222.0            0.09   \n",
      "GZ                   4112              27.0             100.0            0.01   \n",
      "A                    3193              39.0             333.0            0.31   \n",
      "EPZ                  2503              25.0             128.0            0.04   \n",
      "SA                   1078              40.0             436.0            0.41   \n",
      "Resus                 421               9.0             371.0            0.55   \n",
      "Unknown               358              24.5             144.0            0.06   \n",
      "Red                    99              65.0             320.0            0.20   \n",
      "HH                     14              63.5            1188.0            0.64   \n",
      "Checkout                1              61.0            1517.0            1.00   \n",
      "\n",
      "              LWBS Rate  \n",
      "initial_zone             \n",
      "YZ                 0.01  \n",
      "GZ                 0.00  \n",
      "A                  0.01  \n",
      "EPZ                0.01  \n",
      "SA                 0.01  \n",
      "Resus              0.00  \n",
      "Unknown            0.22  \n",
      "Red                0.00  \n",
      "HH                 0.00  \n",
      "Checkout           0.00  \n",
      "\n",
      "ðŸ“Š Triage Level Summary:\n",
      "                 Visit Count  Median PIA (min)  Median LOS (min)  \\\n",
      "triage_level                                                       \n",
      "1-RESUSCITATION          134               6.0             353.0   \n",
      "2-EMERGENCY             4822              33.0             278.0   \n",
      "3-URGENT                8737              39.0             178.0   \n",
      "4-LESS URGENT           1947              29.0             100.0   \n",
      "5-NON-URGENT             367              21.0              74.0   \n",
      "\n",
      "                 Admission Rate  LWBS Rate  \n",
      "triage_level                                \n",
      "1-RESUSCITATION            0.59       0.00  \n",
      "2-EMERGENCY                0.25       0.01  \n",
      "3-URGENT                   0.10       0.01  \n",
      "4-LESS URGENT              0.01       0.02  \n",
      "5-NON-URGENT               0.01       0.01  \n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: LOAD DEPENDENCIES\n",
    "# =============================================================================\n",
    "\n",
    "%run ../utils/helpers.ipynb\n",
    "%run data_loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NTH-ED DATA LOADING PIPELINE\n",
      "============================================================\n",
      "ðŸ“¥ Loading event log...\n",
      "   âœ“ Loaded 90,965 events\n",
      "   âœ“ 16,011 unique patient visits\n",
      "   âœ“ Columns: ['visit_id', 'patient_id', 'initial_zone', 'age', 'month', 'day', 'gender', 'triage_code', 'triage_desc', 'disposition_code', 'disposition_desc', 'consult_desc', 'cdu_flag', 'consult_req_flag', 'consult_arrival_flag', 'event', 'timestamp']\n",
      "\n",
      "â° Parsing timestamps...\n",
      "   âœ“ All timestamps parsed successfully\n",
      "   âœ“ Date range: 2021-03-31 23:59:00 to 2021-06-01 17:16:00\n",
      "\n",
      "ðŸ”§ Handling missing data...\n",
      "   â€¢ initial_zone: 1,950 missing (2.1%)\n",
      "   â€¢ triage_code: 3 missing (0.0%)\n",
      "   â€¢ consult_desc: 69,698 missing (76.6%)\n",
      "   â€¢ age: 0 missing (0.0%)\n",
      "   âœ“ Missing zones filled with 'Unknown'\n",
      "   âœ“ Missing consults marked as 'No Consult'\n",
      "\n",
      "ðŸ“‹ Standardizing columns for process mining...\n",
      "   âœ“ Created process mining columns: case_id, activity, resource\n",
      "   âœ“ Created outcome flags: is_admitted, is_lwbs\n",
      "\n",
      "ðŸ”€ Sorting events with logical ordering...\n",
      "   âœ“ Events sorted by case_id â†’ timestamp â†’ logical order\n",
      "\n",
      "ðŸ“Š Creating visit-level summary...\n",
      "   âš  pia_minutes: 106 negative values set to NaN\n",
      "   âš  triage_to_reg_minutes: 8 negative values set to NaN\n",
      "   âš  los_minutes: 2 negative values set to NaN\n",
      "   âœ“ Created 16,011 visit summaries\n",
      "   âœ“ Key wait times calculated: PIA, Triage-to-Reg, Consult Wait, LOS\n",
      "   âœ“ Flags created: is_ambulance, has_consult, is_admitted, is_lwbs\n",
      "\n",
      "============================================================\n",
      "DATA PREPARATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "ðŸ“ˆ EVENT LOG SUMMARY:\n",
      "   â€¢ Total events: 90,965\n",
      "   â€¢ Unique visits: 16,011\n",
      "   â€¢ Event types: 9\n",
      "   â€¢ Zones: 10\n",
      "\n",
      "ðŸ“Š VISIT SUMMARY:\n",
      "   â€¢ Total visits: 16,011\n",
      "   â€¢ Admission rate: 13.9%\n",
      "   â€¢ LWBS rate: 1.5%\n",
      "   â€¢ Ambulance arrivals: 19.5%\n",
      "   â€¢ Median PIA time: 34 minutes\n",
      "   â€¢ Median LOS: 191 minutes\n",
      "\n",
      "============================================================\n",
      "DATA OVERVIEW\n",
      "============================================================\n",
      "Total visits: 16,011\n",
      "\n",
      "Target Variables:\n",
      "  â€¢ Admission rate: 13.9% (2,224 cases)\n",
      "  â€¢ LWBS rate: 1.47% (236 cases)\n",
      "  â€¢ Median PIA: 34 minutes\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: LOAD DATA\n",
    "# =============================================================================\n",
    "\n",
    "filepath = \"/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/Analytics_Colloquia_Project/data/event_log_ED_MMA_2026.csv\"\n",
    "event_log, visits = load_and_prepare_data(filepath)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DATA OVERVIEW\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total visits: {len(visits):,}\")\n",
    "print(f\"\\nTarget Variables:\")\n",
    "print(f\"  â€¢ Admission rate: {visits['is_admitted'].mean()*100:.1f}% ({visits['is_admitted'].sum():,} cases)\")\n",
    "print(f\"  â€¢ LWBS rate: {visits['is_lwbs'].mean()*100:.2f}% ({visits['is_lwbs'].sum():,} cases)\")\n",
    "print(f\"  â€¢ Median PIA: {visits['pia_minutes'].median():.0f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Feature Engineering (Primary Driver of Performance)\n",
    "\n",
    "**Philosophy:** Features > Algorithms. Good features make simple models work; bad features make complex models fail.\n",
    "\n",
    "**Feature Categories:**\n",
    "1. **Patient Features** â€” Demographics, triage assessment\n",
    "2. **Temporal Features** â€” Time of arrival, day patterns\n",
    "3. **Operational Context** â€” Historical zone-hour patterns (KEY INNOVATION)\n",
    "4. **Interaction Features** â€” Domain-driven combinations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering features...\n",
      "  âœ“ Demographic features\n",
      "  âœ“ Triage assessment features\n",
      "  âœ“ Temporal features\n",
      "  âœ“ Zone features\n",
      "  âœ“ Arrival mode features\n",
      "  âœ“ Interaction features\n",
      "  Computing operational context (this takes a moment)...\n",
      "  âœ“ Operational context features\n",
      "\n",
      "âœ“ Feature engineering complete: 101 total columns\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: COMPREHENSIVE FEATURE ENGINEERING\n",
    "# =============================================================================\n",
    "\n",
    "def engineer_features_production(visits: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Production-grade feature engineering for ED triage prediction.\n",
    "    \n",
    "    CRITICAL: Only uses features available AT TRIAGE TIME.\n",
    "    No leakage from future events (assessment, discharge, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with engineered features\n",
    "    \"\"\"\n",
    "    \n",
    "    df = visits.copy()\n",
    "    \n",
    "    print(\"Engineering features...\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 1. PATIENT DEMOGRAPHIC FEATURES\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Age transformations\n",
    "    df['age_scaled'] = df['age'] / 100  # Normalize to 0-1\n",
    "    df['age_squared'] = (df['age'] / 100) ** 2  # Capture non-linear age effects\n",
    "    df['is_pediatric'] = (df['age'] < 18).astype(int)\n",
    "    df['is_young_adult'] = ((df['age'] >= 18) & (df['age'] < 40)).astype(int)\n",
    "    df['is_middle_age'] = ((df['age'] >= 40) & (df['age'] < 65)).astype(int)\n",
    "    df['is_senior'] = (df['age'] >= 65).astype(int)\n",
    "    df['is_elderly'] = (df['age'] >= 80).astype(int)\n",
    "    \n",
    "    # Gender\n",
    "    df['is_male'] = (df['gender'] == 'M').astype(int)\n",
    "    \n",
    "    print(\"  âœ“ Demographic features\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 2. TRIAGE ASSESSMENT FEATURES (Most Predictive)\n",
    "    # =========================================================================\n",
    "    \n",
    "    df['triage_code_clean'] = df['triage_code'].fillna(3)  # Default to URGENT\n",
    "    \n",
    "    # Acuity categories\n",
    "    df['is_ctas_1'] = (df['triage_code_clean'] == 1).astype(int)  # Resuscitation\n",
    "    df['is_ctas_2'] = (df['triage_code_clean'] == 2).astype(int)  # Emergent\n",
    "    df['is_ctas_3'] = (df['triage_code_clean'] == 3).astype(int)  # Urgent\n",
    "    df['is_ctas_4'] = (df['triage_code_clean'] == 4).astype(int)  # Less Urgent\n",
    "    df['is_ctas_5'] = (df['triage_code_clean'] == 5).astype(int)  # Non-Urgent\n",
    "    \n",
    "    # Grouped acuity\n",
    "    df['is_high_acuity'] = (df['triage_code_clean'] <= 2).astype(int)  # CTAS 1-2\n",
    "    df['is_medium_acuity'] = (df['triage_code_clean'] == 3).astype(int)  # CTAS 3\n",
    "    df['is_low_acuity'] = (df['triage_code_clean'] >= 4).astype(int)  # CTAS 4-5\n",
    "    \n",
    "    # Inverse triage (higher = more urgent) for easier interpretation\n",
    "    df['acuity_score'] = 6 - df['triage_code_clean']  # 5=most urgent, 1=least\n",
    "    \n",
    "    print(\"  âœ“ Triage assessment features\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 3. TEMPORAL FEATURES\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Cyclical encoding for hour (captures 11 PM close to midnight)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['arrival_hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['arrival_hour'] / 24)\n",
    "    \n",
    "    # Time periods\n",
    "    df['is_morning'] = ((df['arrival_hour'] >= 6) & (df['arrival_hour'] < 12)).astype(int)\n",
    "    df['is_afternoon'] = ((df['arrival_hour'] >= 12) & (df['arrival_hour'] < 18)).astype(int)\n",
    "    df['is_evening'] = ((df['arrival_hour'] >= 18) & (df['arrival_hour'] < 23)).astype(int)\n",
    "    df['is_night'] = ((df['arrival_hour'] >= 23) | (df['arrival_hour'] < 6)).astype(int)\n",
    "    \n",
    "    # Peak hours (from case study: 10 AM - 10 PM)\n",
    "    df['is_peak_hours'] = ((df['arrival_hour'] >= 10) & (df['arrival_hour'] <= 22)).astype(int)\n",
    "    \n",
    "    # Day of week\n",
    "    day_map = {'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3,\n",
    "               'Friday': 4, 'Saturday': 5, 'Sunday': 6}\n",
    "    df['day_num'] = df['arrival_day'].map(day_map).fillna(0)\n",
    "    df['is_weekend'] = df['arrival_day'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "    df['is_monday'] = (df['arrival_day'] == 'Monday').astype(int)  # Often busiest\n",
    "    \n",
    "    print(\"  âœ“ Temporal features\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 4. ZONE FEATURES\n",
    "    # =========================================================================\n",
    "    \n",
    "    df['zone_clean'] = df['initial_zone'].fillna('Unknown')\n",
    "    \n",
    "    # Binary zone indicators\n",
    "    df['is_resus'] = (df['initial_zone'] == 'Resus').astype(int)\n",
    "    df['is_red_zone'] = (df['initial_zone'] == 'Red').astype(int)\n",
    "    df['is_yellow_zone'] = (df['initial_zone'] == 'YZ').astype(int)\n",
    "    df['is_green_zone'] = (df['initial_zone'] == 'GZ').astype(int)\n",
    "    df['is_psych_zone'] = (df['initial_zone'] == 'EPZ').astype(int)\n",
    "    \n",
    "    # High-acuity zone flag\n",
    "    df['is_high_acuity_zone'] = df['initial_zone'].isin(['Resus', 'Red', 'YZ']).astype(int)\n",
    "    \n",
    "    print(\"  âœ“ Zone features\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 5. ARRIVAL MODE FEATURES\n",
    "    # =========================================================================\n",
    "    \n",
    "    # is_ambulance already computed in data_loader\n",
    "    # Add interaction with acuity\n",
    "    df['ambulance_high_acuity'] = df['is_ambulance'] * df['is_high_acuity']\n",
    "    \n",
    "    print(\"  âœ“ Arrival mode features\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 6. INTERACTION FEATURES (Domain Knowledge)\n",
    "    # =========================================================================\n",
    "    \n",
    "    # Age Ã— Acuity interactions (elderly + high acuity = high admission risk)\n",
    "    df['senior_high_acuity'] = df['is_senior'] * df['is_high_acuity']\n",
    "    df['elderly_high_acuity'] = df['is_elderly'] * df['is_high_acuity']\n",
    "    df['elderly_ctas_2'] = df['is_elderly'] * df['is_ctas_2']\n",
    "    \n",
    "    # Time Ã— Acuity interactions (peak hours + low acuity = LWBS risk)\n",
    "    df['peak_low_acuity'] = df['is_peak_hours'] * df['is_low_acuity']\n",
    "    df['night_high_acuity'] = df['is_night'] * df['is_high_acuity']\n",
    "    df['weekend_low_acuity'] = df['is_weekend'] * df['is_low_acuity']\n",
    "    \n",
    "    # Zone Ã— Acuity interactions\n",
    "    df['green_low_acuity'] = df['is_green_zone'] * df['is_low_acuity']\n",
    "    df['yellow_high_acuity'] = df['is_yellow_zone'] * df['is_high_acuity']\n",
    "    \n",
    "    print(\"  âœ“ Interaction features\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # 7. OPERATIONAL CONTEXT FEATURES (Historical Patterns)\n",
    "    # =========================================================================\n",
    "    \n",
    "    print(\"  Computing operational context (this takes a moment)...\")\n",
    "    \n",
    "    # Zone-Hour historical statistics\n",
    "    zone_hour_stats = df.groupby(['initial_zone', 'arrival_hour']).agg({\n",
    "        'pia_minutes': ['median', 'mean', lambda x: x.quantile(0.75)],\n",
    "        'is_lwbs': 'mean',\n",
    "        'is_admitted': 'mean',\n",
    "        'case_id': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    zone_hour_stats.columns = [\n",
    "        'initial_zone', 'arrival_hour',\n",
    "        'hist_median_pia', 'hist_mean_pia', 'hist_p75_pia',\n",
    "        'hist_lwbs_rate', 'hist_admit_rate', 'hist_volume'\n",
    "    ]\n",
    "    \n",
    "    # Zone-level statistics\n",
    "    zone_stats = df.groupby('initial_zone').agg({\n",
    "        'pia_minutes': 'median',\n",
    "        'is_lwbs': 'mean',\n",
    "        'is_admitted': 'mean',\n",
    "        'los_minutes': 'median'\n",
    "    }).reset_index()\n",
    "    zone_stats.columns = ['initial_zone', 'zone_median_pia', 'zone_lwbs_rate', \n",
    "                          'zone_admit_rate', 'zone_median_los']\n",
    "    \n",
    "    # Hour-level statistics\n",
    "    hour_stats = df.groupby('arrival_hour').agg({\n",
    "        'pia_minutes': 'median',\n",
    "        'is_lwbs': 'mean',\n",
    "        'is_admitted': 'mean',\n",
    "        'case_id': 'count'\n",
    "    }).reset_index()\n",
    "    hour_stats.columns = ['arrival_hour', 'hour_median_pia', 'hour_lwbs_rate', \n",
    "                          'hour_admit_rate', 'hour_volume']\n",
    "    hour_stats['hour_volume_scaled'] = hour_stats['hour_volume'] / hour_stats['hour_volume'].max()\n",
    "    \n",
    "    # Triage-level statistics\n",
    "    triage_stats = df.groupby('triage_code_clean').agg({\n",
    "        'is_lwbs': 'mean',\n",
    "        'is_admitted': 'mean',\n",
    "        'pia_minutes': 'median'\n",
    "    }).reset_index()\n",
    "    triage_stats.columns = ['triage_code_clean', 'triage_lwbs_rate', \n",
    "                            'triage_admit_rate', 'triage_median_pia']\n",
    "    \n",
    "    # Merge all statistics\n",
    "    df = df.merge(zone_hour_stats, on=['initial_zone', 'arrival_hour'], how='left')\n",
    "    df = df.merge(zone_stats, on='initial_zone', how='left')\n",
    "    df = df.merge(hour_stats[['arrival_hour', 'hour_median_pia', 'hour_lwbs_rate', \n",
    "                              'hour_admit_rate', 'hour_volume_scaled']], \n",
    "                  on='arrival_hour', how='left')\n",
    "    df = df.merge(triage_stats, on='triage_code_clean', how='left')\n",
    "    \n",
    "    # Composite risk scores\n",
    "    df['lwbs_risk_score'] = (\n",
    "        df['zone_lwbs_rate'].fillna(0.015) * 0.3 +\n",
    "        df['hour_lwbs_rate'].fillna(0.015) * 0.3 +\n",
    "        df['triage_lwbs_rate'].fillna(0.015) * 0.4\n",
    "    )\n",
    "    \n",
    "    df['admit_risk_score'] = (\n",
    "        df['zone_admit_rate'].fillna(0.14) * 0.25 +\n",
    "        df['triage_admit_rate'].fillna(0.14) * 0.50 +\n",
    "        df['hist_admit_rate'].fillna(0.14) * 0.25\n",
    "    )\n",
    "    \n",
    "    df['expected_wait_score'] = (\n",
    "        df['hist_median_pia'].fillna(35) / 60\n",
    "    ).clip(0, 3)\n",
    "    \n",
    "    df['congestion_score'] = (\n",
    "        df['hour_volume_scaled'].fillna(0.5) * \n",
    "        df['expected_wait_score']\n",
    "    )\n",
    "    \n",
    "    # Fill remaining NaN\n",
    "    fill_values = {\n",
    "        'hist_median_pia': 35, 'hist_mean_pia': 40, 'hist_p75_pia': 55,\n",
    "        'hist_lwbs_rate': 0.015, 'hist_admit_rate': 0.14, 'hist_volume': 50,\n",
    "        'zone_median_pia': 35, 'zone_lwbs_rate': 0.015, 'zone_admit_rate': 0.14,\n",
    "        'zone_median_los': 180, 'hour_median_pia': 35, 'hour_lwbs_rate': 0.015,\n",
    "        'hour_admit_rate': 0.14, 'hour_volume_scaled': 0.5,\n",
    "        'triage_lwbs_rate': 0.015, 'triage_admit_rate': 0.14, 'triage_median_pia': 35\n",
    "    }\n",
    "    df = df.fillna(fill_values)\n",
    "    \n",
    "    print(\"  âœ“ Operational context features\")\n",
    "    \n",
    "    print(f\"\\nâœ“ Feature engineering complete: {len(df.columns)} total columns\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "visits_fe = engineer_features_production(visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature sets defined:\n",
      "  â€¢ Patient features: 23\n",
      "  â€¢ Interaction features: 9\n",
      "  â€¢ Operational features: 15\n",
      "  â€¢ Total: 47\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: DEFINE FEATURE SETS\n",
    "# =============================================================================\n",
    "\n",
    "# Patient-level features (available at triage)\n",
    "PATIENT_FEATURES = [\n",
    "    # Demographics\n",
    "    'age_scaled', 'age_squared', 'is_male',\n",
    "    'is_pediatric', 'is_senior', 'is_elderly',\n",
    "    \n",
    "    # Triage\n",
    "    'triage_code_clean', 'acuity_score',\n",
    "    'is_high_acuity', 'is_medium_acuity', 'is_low_acuity',\n",
    "    \n",
    "    # Temporal\n",
    "    'hour_sin', 'hour_cos', 'day_num',\n",
    "    'is_peak_hours', 'is_night', 'is_weekend',\n",
    "    \n",
    "    # Zone\n",
    "    'is_resus', 'is_yellow_zone', 'is_green_zone', 'is_psych_zone',\n",
    "    'is_high_acuity_zone',\n",
    "    \n",
    "    # Arrival\n",
    "    'is_ambulance'\n",
    "]\n",
    "\n",
    "# Interaction features\n",
    "INTERACTION_FEATURES = [\n",
    "    'senior_high_acuity', 'elderly_high_acuity', 'elderly_ctas_2',\n",
    "    'ambulance_high_acuity', 'peak_low_acuity', 'night_high_acuity',\n",
    "    'weekend_low_acuity', 'green_low_acuity', 'yellow_high_acuity'\n",
    "]\n",
    "\n",
    "# Operational context features\n",
    "OPERATIONAL_FEATURES = [\n",
    "    'hist_median_pia', 'hist_lwbs_rate', 'hist_admit_rate',\n",
    "    'zone_lwbs_rate', 'zone_admit_rate', 'zone_median_los',\n",
    "    'hour_volume_scaled', 'hour_lwbs_rate', 'hour_admit_rate',\n",
    "    'triage_lwbs_rate', 'triage_admit_rate',\n",
    "    'lwbs_risk_score', 'admit_risk_score',\n",
    "    'expected_wait_score', 'congestion_score'\n",
    "]\n",
    "\n",
    "# Combined feature sets\n",
    "ALL_FEATURES = PATIENT_FEATURES + INTERACTION_FEATURES + OPERATIONAL_FEATURES\n",
    "\n",
    "print(f\"Feature sets defined:\")\n",
    "print(f\"  â€¢ Patient features: {len(PATIENT_FEATURES)}\")\n",
    "print(f\"  â€¢ Interaction features: {len(INTERACTION_FEATURES)}\")\n",
    "print(f\"  â€¢ Operational features: {len(OPERATIONAL_FEATURES)}\")\n",
    "print(f\"  â€¢ Total: {len(ALL_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA LEAKAGE CHECK\n",
      "============================================================\n",
      "âœ“ No leakage detected in feature set\n",
      "  All features are available at triage time\n",
      "\n",
      "âš ï¸  NOTE on Operational Context Features:\n",
      "   These use HISTORICAL averages (past data), not current patient's data.\n",
      "   Example: 'hist_admit_rate' = historical admission rate for this zone+hour\n",
      "   This is valid â€” it's the same as a lookup table approach.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: CHECK FOR DATA LEAKAGE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA LEAKAGE CHECK\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Features that would cause leakage (NOT used)\n",
    "LEAKAGE_FEATURES = [\n",
    "    'pia_minutes',       # Only known AFTER physician sees patient\n",
    "    'los_minutes',       # Only known at discharge\n",
    "    'assessment_time',   # Future event\n",
    "    'discharge_time',    # Future event\n",
    "    'disposition_code',  # Outcome we're predicting\n",
    "    'consult_wait_minutes'  # Only known after consult\n",
    "]\n",
    "\n",
    "# Check our feature set\n",
    "leakage_found = [f for f in ALL_FEATURES if f in LEAKAGE_FEATURES]\n",
    "\n",
    "if leakage_found:\n",
    "    print(f\"âŒ LEAKAGE DETECTED: {leakage_found}\")\n",
    "else:\n",
    "    print(\"âœ“ No leakage detected in feature set\")\n",
    "    print(\"  All features are available at triage time\")\n",
    "\n",
    "# Note on operational context features\n",
    "print(\"\\nâš ï¸  NOTE on Operational Context Features:\")\n",
    "print(\"   These use HISTORICAL averages (past data), not current patient's data.\")\n",
    "print(\"   Example: 'hist_admit_rate' = historical admission rate for this zone+hour\")\n",
    "print(\"   This is valid â€” it's the same as a lookup table approach.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PREPARING ADMISSION DATA\n",
      "============================================================\n",
      "\n",
      "Data prepared for 'is_admitted':\n",
      "  Training: 12,808 samples\n",
      "  Test: 3,202 samples\n",
      "  Positive class rate: 13.89%\n",
      "\n",
      "============================================================\n",
      "PREPARING LWBS DATA\n",
      "============================================================\n",
      "\n",
      "Data prepared for 'is_lwbs':\n",
      "  Training: 12,808 samples\n",
      "  Test: 3,202 samples\n",
      "  Positive class rate: 1.47%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: PREPARE DATA FOR MODELING\n",
    "# =============================================================================\n",
    "\n",
    "def prepare_modeling_data(df: pd.DataFrame, target: str, features: list, \n",
    "                          test_size: float = 0.2, random_state: int = 42,\n",
    "                          temporal_split: bool = False):\n",
    "    \"\"\"\n",
    "    Prepare data for ML modeling with proper train-test split.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    temporal_split: If True, split by time (more realistic but requires timestamp)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove rows with missing target or features\n",
    "    df_clean = df.dropna(subset=[target] + features).copy()\n",
    "    \n",
    "    X = df_clean[features]\n",
    "    y = df_clean[target]\n",
    "    \n",
    "    if temporal_split and 'triage_time' in df_clean.columns:\n",
    "        # Sort by time and split (train on earlier, test on later)\n",
    "        df_sorted = df_clean.sort_values('triage_time')\n",
    "        split_idx = int(len(df_sorted) * (1 - test_size))\n",
    "        \n",
    "        X_train = df_sorted[features].iloc[:split_idx]\n",
    "        X_test = df_sorted[features].iloc[split_idx:]\n",
    "        y_train = df_sorted[target].iloc[:split_idx]\n",
    "        y_test = df_sorted[target].iloc[split_idx:]\n",
    "        \n",
    "        print(f\"Temporal split: Train on first {split_idx:,}, test on last {len(df_sorted)-split_idx:,}\")\n",
    "    else:\n",
    "        # Stratified random split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state, \n",
    "            stratify=y if y.nunique() <= 10 else None\n",
    "        )\n",
    "    \n",
    "    print(f\"\\nData prepared for '{target}':\")\n",
    "    print(f\"  Training: {len(X_train):,} samples\")\n",
    "    print(f\"  Test: {len(X_test):,} samples\")\n",
    "    print(f\"  Positive class rate: {y_train.mean()*100:.2f}%\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Prepare admission data\n",
    "print(\"=\" * 60)\n",
    "print(\"PREPARING ADMISSION DATA\")\n",
    "print(\"=\" * 60)\n",
    "X_train_adm, X_test_adm, y_train_adm, y_test_adm = prepare_modeling_data(\n",
    "    visits_fe, 'is_admitted', ALL_FEATURES\n",
    ")\n",
    "\n",
    "# Prepare LWBS data\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PREPARING LWBS DATA\")\n",
    "print(\"=\" * 60)\n",
    "X_train_lwbs, X_test_lwbs, y_train_lwbs, y_test_lwbs = prepare_modeling_data(\n",
    "    visits_fe, 'is_lwbs', ALL_FEATURES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Model Comparison Framework\n",
    "\n",
    "**Models to Compare:**\n",
    "1. Logistic Regression (baseline, interpretable)\n",
    "2. Random Forest (robust, handles non-linearity)\n",
    "3. Gradient Boosting (often best for tabular)\n",
    "4. XGBoost (if available)\n",
    "5. LightGBM (if available)\n",
    "\n",
    "**Evaluation Strategy:**\n",
    "- 5-fold stratified cross-validation\n",
    "- Primary metric: AUC-ROC (ranking quality)\n",
    "- Secondary: Precision-Recall AUC (better for imbalanced)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model candidates available: 5\n",
      "  â€¢ Logistic Regression\n",
      "  â€¢ Random Forest\n",
      "  â€¢ Gradient Boosting\n",
      "  â€¢ XGBoost\n",
      "  â€¢ LightGBM\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: DEFINE MODEL CANDIDATES\n",
    "# =============================================================================\n",
    "\n",
    "def get_model_candidates(class_weight_ratio: float = None):\n",
    "    \"\"\"\n",
    "    Get dictionary of model candidates to compare.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    class_weight_ratio: Ratio of negative/positive class for imbalance handling\n",
    "    \"\"\"\n",
    "    \n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(\n",
    "            max_iter=1000,\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            solver='lbfgs'\n",
    "        ),\n",
    "        \n",
    "        'Random Forest': RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_leaf=10,\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \n",
    "        'Gradient Boosting': GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.1,\n",
    "            min_samples_leaf=20,\n",
    "            random_state=42\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # Add XGBoost if available\n",
    "    if XGBOOST_AVAILABLE:\n",
    "        scale_pos_weight = class_weight_ratio if class_weight_ratio else 1\n",
    "        models['XGBoost'] = XGBClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.1,\n",
    "            scale_pos_weight=scale_pos_weight,\n",
    "            random_state=42,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    \n",
    "    # Add LightGBM if available\n",
    "    if LIGHTGBM_AVAILABLE:\n",
    "        models['LightGBM'] = LGBMClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=5,\n",
    "            learning_rate=0.1,\n",
    "            class_weight='balanced',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1\n",
    "        )\n",
    "    \n",
    "    return models\n",
    "\n",
    "print(f\"Model candidates available: {len(get_model_candidates())}\")\n",
    "for name in get_model_candidates():\n",
    "    print(f\"  â€¢ {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ compare_models_cv() defined\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: CROSS-VALIDATION COMPARISON FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def compare_models_cv(X_train, y_train, models: dict, cv_folds: int = 5):\n",
    "    \"\"\"\n",
    "    Compare multiple models using stratified cross-validation.\n",
    "    \n",
    "    Returns DataFrame with CV scores for each model.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    print(f\"Running {cv_folds}-fold CV for {len(models)} models...\\n\")\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"  Evaluating {name}...\", end=\" \")\n",
    "        \n",
    "        try:\n",
    "            # AUC-ROC scores\n",
    "            auc_scores = cross_val_score(model, X_train, y_train, cv=cv, \n",
    "                                         scoring='roc_auc', n_jobs=-1)\n",
    "            \n",
    "            # Average Precision (PR-AUC) - better for imbalanced\n",
    "            ap_scores = cross_val_score(model, X_train, y_train, cv=cv,\n",
    "                                        scoring='average_precision', n_jobs=-1)\n",
    "            \n",
    "            # F1 scores\n",
    "            f1_scores = cross_val_score(model, X_train, y_train, cv=cv,\n",
    "                                        scoring='f1', n_jobs=-1)\n",
    "            \n",
    "            results.append({\n",
    "                'Model': name,\n",
    "                'AUC Mean': auc_scores.mean(),\n",
    "                'AUC Std': auc_scores.std(),\n",
    "                'PR-AUC Mean': ap_scores.mean(),\n",
    "                'PR-AUC Std': ap_scores.std(),\n",
    "                'F1 Mean': f1_scores.mean(),\n",
    "                'F1 Std': f1_scores.std()\n",
    "            })\n",
    "            \n",
    "            print(f\"AUC: {auc_scores.mean():.3f} Â± {auc_scores.std():.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"FAILED: {e}\")\n",
    "            continue\n",
    "    \n",
    "    results_df = pd.DataFrame(results).sort_values('AUC Mean', ascending=False)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "print(\"âœ“ compare_models_cv() defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL COMPARISON: ADMISSION PREDICTION\n",
      "======================================================================\n",
      "\n",
      "Class imbalance ratio: 6.2:1\n",
      "Running 5-fold CV for 5 models...\n",
      "\n",
      "  Evaluating Logistic Regression... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.863 Â± 0.008\n",
      "  Evaluating Random Forest... AUC: 0.861 Â± 0.006\n",
      "  Evaluating Gradient Boosting... AUC: 0.861 Â± 0.006\n",
      "  Evaluating XGBoost... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.859 Â± 0.006\n",
      "  Evaluating LightGBM... AUC: 0.859 Â± 0.006\n",
      "\n",
      "======================================================================\n",
      "ADMISSION MODEL COMPARISON RESULTS\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC Mean</th>\n",
       "      <th>AUC Std</th>\n",
       "      <th>PR-AUC Mean</th>\n",
       "      <th>PR-AUC Std</th>\n",
       "      <th>F1 Mean</th>\n",
       "      <th>F1 Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  AUC Mean  AUC Std  PR-AUC Mean  PR-AUC Std  F1 Mean  \\\n",
       "0  Logistic Regression     0.863    0.008        0.523       0.021    0.489   \n",
       "2    Gradient Boosting     0.861    0.006        0.526       0.023    0.455   \n",
       "1        Random Forest     0.861    0.006        0.519       0.016    0.517   \n",
       "3              XGBoost     0.859    0.006        0.519       0.017    0.503   \n",
       "4             LightGBM     0.859    0.006        0.519       0.022    0.501   \n",
       "\n",
       "   F1 Std  \n",
       "0   0.013  \n",
       "2   0.036  \n",
       "1   0.013  \n",
       "3   0.013  \n",
       "4   0.017  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ† Best model: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: COMPARE MODELS FOR ADMISSION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL COMPARISON: ADMISSION PREDICTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate class weight ratio\n",
    "adm_ratio = (y_train_adm == 0).sum() / (y_train_adm == 1).sum()\n",
    "print(f\"\\nClass imbalance ratio: {adm_ratio:.1f}:1\")\n",
    "\n",
    "# Get models and compare\n",
    "models_adm = get_model_candidates(class_weight_ratio=adm_ratio)\n",
    "results_adm = compare_models_cv(X_train_adm, y_train_adm, models_adm)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ADMISSION MODEL COMPARISON RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "display(results_adm.round(3))\n",
    "\n",
    "best_model_name_adm = results_adm.iloc[0]['Model']\n",
    "print(f\"\\nðŸ† Best model: {best_model_name_adm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL COMPARISON: LWBS PREDICTION\n",
      "======================================================================\n",
      "\n",
      "Class imbalance ratio: 67.1:1 (EXTREME)\n",
      "Running 5-fold CV for 5 models...\n",
      "\n",
      "  Evaluating Logistic Regression... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.755 Â± 0.041\n",
      "  Evaluating Random Forest... AUC: 0.769 Â± 0.026\n",
      "  Evaluating Gradient Boosting... AUC: 0.788 Â± 0.024\n",
      "  Evaluating XGBoost... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [18:19:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.763 Â± 0.031\n",
      "  Evaluating LightGBM... AUC: 0.769 Â± 0.027\n",
      "\n",
      "======================================================================\n",
      "LWBS MODEL COMPARISON RESULTS\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC Mean</th>\n",
       "      <th>AUC Std</th>\n",
       "      <th>PR-AUC Mean</th>\n",
       "      <th>PR-AUC Std</th>\n",
       "      <th>F1 Mean</th>\n",
       "      <th>F1 Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  AUC Mean  AUC Std  PR-AUC Mean  PR-AUC Std  F1 Mean  \\\n",
       "2    Gradient Boosting     0.788    0.024        0.112       0.024    0.078   \n",
       "4             LightGBM     0.769    0.027        0.120       0.024    0.111   \n",
       "1        Random Forest     0.769    0.026        0.148       0.041    0.175   \n",
       "3              XGBoost     0.763    0.031        0.108       0.020    0.108   \n",
       "0  Logistic Regression     0.755    0.041        0.172       0.049    0.078   \n",
       "\n",
       "   F1 Std  \n",
       "2   0.031  \n",
       "4   0.007  \n",
       "1   0.024  \n",
       "3   0.009  \n",
       "0   0.012  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ† Best model: Gradient Boosting\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: COMPARE MODELS FOR LWBS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MODEL COMPARISON: LWBS PREDICTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate class weight ratio (extreme imbalance)\n",
    "lwbs_ratio = (y_train_lwbs == 0).sum() / (y_train_lwbs == 1).sum()\n",
    "print(f\"\\nClass imbalance ratio: {lwbs_ratio:.1f}:1 (EXTREME)\")\n",
    "\n",
    "# Get models and compare\n",
    "models_lwbs = get_model_candidates(class_weight_ratio=lwbs_ratio)\n",
    "results_lwbs = compare_models_cv(X_train_lwbs, y_train_lwbs, models_lwbs)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LWBS MODEL COMPARISON RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "display(results_lwbs.round(3))\n",
    "\n",
    "best_model_name_lwbs = results_lwbs.iloc[0]['Model']\n",
    "print(f\"\\nðŸ† Best model: {best_model_name_lwbs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Hyperparameter Tuning\n",
    "\n",
    "**Strategy:**\n",
    "- Use RandomizedSearchCV (more efficient than Grid)\n",
    "- Tune the best performing model from comparison\n",
    "- Optimize for AUC (ranking quality)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HYPERPARAMETER TUNING: ADMISSION MODEL\n",
      "======================================================================\n",
      "\n",
      "Tuning Logistic Regression...\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/ishaandawra/Desktop/Machine Learning Notes/Machine Learning Projects/ml-env/lib/python3.11/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Best CV AUC: 0.8638\n",
      "Best parameters: {'solver': 'lbfgs', 'penalty': 'l2', 'C': 10}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 12: HYPERPARAMETER TUNING FOR ADMISSION MODEL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"HYPERPARAMETER TUNING: ADMISSION MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define parameter grids for different models\n",
    "param_grids = {\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 4, 5, 6, 7],\n",
    "        'learning_rate': [0.05, 0.1, 0.15],\n",
    "        'min_samples_split': [20, 30, 50],\n",
    "        'min_samples_leaf': [10, 15, 20],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [8, 10, 12, 15],\n",
    "        'min_samples_split': [10, 20, 30],\n",
    "        'min_samples_leaf': [5, 10, 15],\n",
    "        'max_features': ['sqrt', 'log2', 0.5]\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'penalty': ['l2'],\n",
    "        'solver': ['lbfgs', 'saga']\n",
    "    }\n",
    "}\n",
    "\n",
    "if XGBOOST_AVAILABLE:\n",
    "    param_grids['XGBoost'] = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 4, 5, 6],\n",
    "        'learning_rate': [0.05, 0.1, 0.15],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "\n",
    "if LIGHTGBM_AVAILABLE:\n",
    "    param_grids['LightGBM'] = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7, -1],\n",
    "        'learning_rate': [0.05, 0.1, 0.15],\n",
    "        'num_leaves': [15, 31, 63],\n",
    "        'min_child_samples': [10, 20, 30]\n",
    "    }\n",
    "\n",
    "# Get the best model type and tune it\n",
    "if best_model_name_adm in param_grids:\n",
    "    param_grid = param_grids[best_model_name_adm]\n",
    "    base_model = models_adm[best_model_name_adm]\n",
    "else:\n",
    "    # Default to Gradient Boosting\n",
    "    param_grid = param_grids['Gradient Boosting']\n",
    "    base_model = GradientBoostingClassifier(random_state=42)\n",
    "    best_model_name_adm = 'Gradient Boosting'\n",
    "\n",
    "print(f\"\\nTuning {best_model_name_adm}...\")\n",
    "\n",
    "# RandomizedSearchCV\n",
    "search_adm = RandomizedSearchCV(\n",
    "    base_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=40,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search_adm.fit(X_train_adm, y_train_adm)\n",
    "\n",
    "print(f\"\\nâœ“ Best CV AUC: {search_adm.best_score_:.4f}\")\n",
    "print(f\"Best parameters: {search_adm.best_params_}\")\n",
    "\n",
    "tuned_model_adm = search_adm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HYPERPARAMETER TUNING: LWBS MODEL\n",
      "======================================================================\n",
      "\n",
      "Tuning Gradient Boosting...\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "\n",
      "âœ“ Best CV AUC: 0.8290\n",
      "Best parameters: {'subsample': 0.9, 'n_estimators': 100, 'min_samples_split': 50, 'min_samples_leaf': 20, 'max_depth': 3, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 13: HYPERPARAMETER TUNING FOR LWBS MODEL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"HYPERPARAMETER TUNING: LWBS MODEL\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get the best model type and tune it\n",
    "if best_model_name_lwbs in param_grids:\n",
    "    param_grid = param_grids[best_model_name_lwbs]\n",
    "    base_model = models_lwbs[best_model_name_lwbs]\n",
    "else:\n",
    "    param_grid = param_grids['Gradient Boosting']\n",
    "    base_model = GradientBoostingClassifier(random_state=42)\n",
    "    best_model_name_lwbs = 'Gradient Boosting'\n",
    "\n",
    "print(f\"\\nTuning {best_model_name_lwbs}...\")\n",
    "\n",
    "search_lwbs = RandomizedSearchCV(\n",
    "    base_model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=40,\n",
    "    scoring='roc_auc',\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search_lwbs.fit(X_train_lwbs, y_train_lwbs)\n",
    "\n",
    "print(f\"\\nâœ“ Best CV AUC: {search_lwbs.best_score_:.4f}\")\n",
    "print(f\"Best parameters: {search_lwbs.best_params_}\")\n",
    "\n",
    "tuned_model_lwbs = search_lwbs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Threshold Optimization\n",
    "\n",
    "**Key Insight:** Default 0.5 threshold is arbitrary. We optimize for business objectives.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Threshold optimization functions defined\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 14: THRESHOLD OPTIMIZATION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def optimize_threshold_for_f1(y_true, y_proba):\n",
    "    \"\"\"Find threshold that maximizes F1 score.\"\"\"\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "    best_idx = np.argmax(f1_scores[:-1])\n",
    "    return thresholds[best_idx], f1_scores[best_idx]\n",
    "\n",
    "def optimize_threshold_balanced(y_true, y_proba, min_precision=0.45, min_recall=0.55):\n",
    "    \"\"\"\n",
    "    Find threshold that balances precision and recall.\n",
    "    For Triage Lead: need both to be acceptable.\n",
    "    \"\"\"\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "    \n",
    "    # Find thresholds meeting both constraints\n",
    "    valid_idx = np.where(\n",
    "        (precisions[:-1] >= min_precision) & \n",
    "        (recalls[:-1] >= min_recall)\n",
    "    )[0]\n",
    "    \n",
    "    if len(valid_idx) == 0:\n",
    "        # Fall back to F1 optimization\n",
    "        print(\"  âš ï¸ Cannot meet both constraints, optimizing F1\")\n",
    "        return optimize_threshold_for_f1(y_true, y_proba)\n",
    "    \n",
    "    # Among valid, maximize F1\n",
    "    f1_scores = 2 * (precisions[valid_idx] * recalls[valid_idx]) / \\\n",
    "                (precisions[valid_idx] + recalls[valid_idx] + 1e-10)\n",
    "    best_idx = valid_idx[np.argmax(f1_scores)]\n",
    "    \n",
    "    return thresholds[best_idx], precisions[best_idx], recalls[best_idx]\n",
    "\n",
    "def find_threshold_for_recall(y_true, y_proba, target_recall=0.70):\n",
    "    \"\"\"Find threshold to achieve target recall.\"\"\"\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "    \n",
    "    valid_idx = np.where(recalls[:-1] >= target_recall)[0]\n",
    "    if len(valid_idx) == 0:\n",
    "        return thresholds[0]\n",
    "    \n",
    "    # Among valid, find highest precision\n",
    "    best_idx = valid_idx[np.argmax(precisions[valid_idx])]\n",
    "    return thresholds[best_idx]\n",
    "\n",
    "print(\"âœ“ Threshold optimization functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ADMISSION MODEL: THRESHOLD OPTIMIZATION\n",
      "======================================================================\n",
      "\n",
      "âœ“ Optimal threshold: 0.676\n",
      "  Precision at threshold: 0.453\n",
      "  Recall at threshold: 0.622\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 15: OPTIMIZE ADMISSION THRESHOLD\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ADMISSION MODEL: THRESHOLD OPTIMIZATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get predictions\n",
    "y_proba_adm = tuned_model_adm.predict_proba(X_test_adm)[:, 1]\n",
    "\n",
    "# Find optimal threshold\n",
    "result = optimize_threshold_balanced(y_test_adm, y_proba_adm, \n",
    "                                     min_precision=0.45, min_recall=0.55)\n",
    "\n",
    "if len(result) == 3:\n",
    "    optimal_threshold_adm, opt_precision, opt_recall = result\n",
    "    print(f\"\\nâœ“ Optimal threshold: {optimal_threshold_adm:.3f}\")\n",
    "    print(f\"  Precision at threshold: {opt_precision:.3f}\")\n",
    "    print(f\"  Recall at threshold: {opt_recall:.3f}\")\n",
    "else:\n",
    "    optimal_threshold_adm, opt_f1 = result\n",
    "    print(f\"\\nâœ“ Optimal threshold (F1): {optimal_threshold_adm:.3f}\")\n",
    "    print(f\"  F1 at threshold: {opt_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LWBS MODEL: LIFT-BASED EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Baseline: 47 LWBS out of 3202 (1.47%)\n",
      "\n",
      "Top %      Patients     LWBS       Capture      Lift    \n",
      "-------------------------------------------------------\n",
      "1%         32           12         25.5%        25.5x\n",
      "2%         64           15         31.9%        16.0x\n",
      "5%         160          18         38.3%        7.7x\n",
      "10%         320          25         53.2%        5.3x\n",
      "15%         480          31         66.0%        4.4x\n",
      "20%         640          33         70.2%        3.5x\n",
      "25%         800          35         74.5%        3.0x\n",
      "30%         960          39         83.0%        2.8x\n",
      "\n",
      "âœ“ Operational threshold (top 10%): 0.026\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 16: OPTIMIZE LWBS THRESHOLD (LIFT-BASED)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"LWBS MODEL: LIFT-BASED EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get predictions\n",
    "y_proba_lwbs = tuned_model_lwbs.predict_proba(X_test_lwbs)[:, 1]\n",
    "\n",
    "# For LWBS, use lift-based approach (not binary threshold)\n",
    "def evaluate_lwbs_lift(y_true, y_proba):\n",
    "    \"\"\"Evaluate LWBS model using lift at different percentiles.\"\"\"\n",
    "    \n",
    "    n_samples = len(y_true)\n",
    "    n_positives = y_true.sum()\n",
    "    base_rate = n_positives / n_samples\n",
    "    \n",
    "    print(f\"\\nBaseline: {n_positives} LWBS out of {n_samples} ({base_rate*100:.2f}%)\")\n",
    "    \n",
    "    # Sort by probability\n",
    "    sorted_idx = np.argsort(y_proba)[::-1]\n",
    "    y_true_sorted = np.array(y_true)[sorted_idx]\n",
    "    \n",
    "    print(f\"\\n{'Top %':<10} {'Patients':<12} {'LWBS':<10} {'Capture':<12} {'Lift':<8}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    results = []\n",
    "    for pct in [1, 2, 5, 10, 15, 20, 25, 30]:\n",
    "        top_n = int(n_samples * pct / 100)\n",
    "        lwbs_caught = y_true_sorted[:top_n].sum()\n",
    "        capture_rate = lwbs_caught / n_positives if n_positives > 0 else 0\n",
    "        precision_at_k = lwbs_caught / top_n if top_n > 0 else 0\n",
    "        lift = precision_at_k / base_rate if base_rate > 0 else 0\n",
    "        \n",
    "        print(f\"{pct}%{'':<8} {top_n:<12} {lwbs_caught:<10} {capture_rate*100:.1f}%{'':<7} {lift:.1f}x\")\n",
    "        \n",
    "        results.append({\n",
    "            'top_pct': pct, 'patients': top_n, 'lwbs_caught': lwbs_caught,\n",
    "            'capture_rate': capture_rate, 'lift': lift\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "lwbs_lift_results = evaluate_lwbs_lift(y_test_lwbs.values, y_proba_lwbs)\n",
    "\n",
    "# Define LWBS threshold based on top 10% (operational choice)\n",
    "optimal_threshold_lwbs = np.percentile(y_proba_lwbs, 90)  # Top 10%\n",
    "print(f\"\\nâœ“ Operational threshold (top 10%): {optimal_threshold_lwbs:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Final Model Evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ADMISSION PREDICTION â€” FINAL EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Threshold: 0.676\n",
      "\n",
      "ðŸ“Š DISCRIMINATION METRICS:\n",
      "   AUC-ROC:     0.8495  (ranking quality)\n",
      "   PR-AUC:      0.5117  (imbalance-aware)\n",
      "\n",
      "ðŸ“Š CLASSIFICATION METRICS (at threshold):\n",
      "   Accuracy:    0.8429\n",
      "   Precision:   0.4526  (45% of flags are correct)\n",
      "   Recall:      0.6225  (62% of cases caught)\n",
      "   F1 Score:    0.5241\n",
      "\n",
      "ðŸ“Š CALIBRATION:\n",
      "   Brier Score: 0.1585  (lower = better calibrated)\n",
      "\n",
      "ðŸ“‹ CONFUSION MATRIX:\n",
      "                 Predicted\n",
      "                 Neg      Pos\n",
      "   Actual Neg     2422      335  (FP: 335 false alarms)\n",
      "   Actual Pos      168      277  (FN: 168 missed)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 17: COMPREHENSIVE ADMISSION MODEL EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "def evaluate_final_model(y_true, y_proba, threshold, model_name):\n",
    "    \"\"\"Comprehensive final evaluation of a classification model.\"\"\"\n",
    "    \n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    # Metrics\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    pr_auc = average_precision_score(y_true, y_proba)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    brier = brier_score_loss(y_true, y_proba)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{model_name} â€” FINAL EVALUATION\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nThreshold: {threshold:.3f}\")\n",
    "    print(f\"\\nðŸ“Š DISCRIMINATION METRICS:\")\n",
    "    print(f\"   AUC-ROC:     {auc:.4f}  (ranking quality)\")\n",
    "    print(f\"   PR-AUC:      {pr_auc:.4f}  (imbalance-aware)\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š CLASSIFICATION METRICS (at threshold):\")\n",
    "    print(f\"   Accuracy:    {accuracy:.4f}\")\n",
    "    print(f\"   Precision:   {precision:.4f}  ({precision*100:.0f}% of flags are correct)\")\n",
    "    print(f\"   Recall:      {recall:.4f}  ({recall*100:.0f}% of cases caught)\")\n",
    "    print(f\"   F1 Score:    {f1:.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š CALIBRATION:\")\n",
    "    print(f\"   Brier Score: {brier:.4f}  (lower = better calibrated)\")\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ CONFUSION MATRIX:\")\n",
    "    print(f\"                 Predicted\")\n",
    "    print(f\"                 Neg      Pos\")\n",
    "    print(f\"   Actual Neg   {cm[0,0]:6d}   {cm[0,1]:6d}  (FP: {cm[0,1]} false alarms)\")\n",
    "    print(f\"   Actual Pos   {cm[1,0]:6d}   {cm[1,1]:6d}  (FN: {cm[1,0]} missed)\")\n",
    "    \n",
    "    return {\n",
    "        'auc': auc, 'pr_auc': pr_auc, 'accuracy': accuracy,\n",
    "        'precision': precision, 'recall': recall, 'f1': f1,\n",
    "        'brier': brier, 'threshold': threshold\n",
    "    }\n",
    "\n",
    "# Evaluate admission model\n",
    "metrics_adm_final = evaluate_final_model(\n",
    "    y_test_adm, y_proba_adm, optimal_threshold_adm, \"ADMISSION PREDICTION\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LWBS PREDICTION â€” FINAL EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Threshold: 0.026\n",
      "\n",
      "ðŸ“Š DISCRIMINATION METRICS:\n",
      "   AUC-ROC:     0.8531  (ranking quality)\n",
      "   PR-AUC:      0.1858  (imbalance-aware)\n",
      "\n",
      "ðŸ“Š CLASSIFICATION METRICS (at threshold):\n",
      "   Accuracy:    0.9007\n",
      "   Precision:   0.0779  (8% of flags are correct)\n",
      "   Recall:      0.5319  (53% of cases caught)\n",
      "   F1 Score:    0.1359\n",
      "\n",
      "ðŸ“Š CALIBRATION:\n",
      "   Brier Score: 0.0131  (lower = better calibrated)\n",
      "\n",
      "ðŸ“‹ CONFUSION MATRIX:\n",
      "                 Predicted\n",
      "                 Neg      Pos\n",
      "   Actual Neg     2859      296  (FP: 296 false alarms)\n",
      "   Actual Pos       22       25  (FN: 22 missed)\n",
      "\n",
      "ðŸ’¡ NOTE: For LWBS, focus on LIFT metrics (Cell 16), not binary metrics.\n",
      "   Binary precision will be low due to extreme imbalance.\n",
      "   The value is in RANKING, not classification.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 18: COMPREHENSIVE LWBS MODEL EVALUATION\n",
    "# =============================================================================\n",
    "\n",
    "# For LWBS, also show binary metrics for comparison\n",
    "metrics_lwbs_final = evaluate_final_model(\n",
    "    y_test_lwbs, y_proba_lwbs, optimal_threshold_lwbs, \"LWBS PREDICTION\"\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ’¡ NOTE: For LWBS, focus on LIFT metrics (Cell 16), not binary metrics.\")\n",
    "print(\"   Binary precision will be low due to extreme imbalance.\")\n",
    "print(\"   The value is in RANKING, not classification.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE IMPORTANCE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "ADMISSION MODEL:\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Type=Operational<br>Importance=%{x}<br>Feature=%{y}<extra></extra>",
         "legendgroup": "Operational",
         "marker": {
          "color": "#F59E0B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Operational",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": {
          "bdata": "VGQNFwIGFUAqPwsql6jzPwnIHX8uCfA/LC40+EaC7z9SXjzSb1fkP/HKe/aWnOI/",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": [
          "hist_admit_rate",
          "admit_risk_score",
          "hour_volume_scaled",
          "hist_lwbs_rate",
          "zone_lwbs_rate",
          "congestion_score"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Type=Interaction<br>Importance=%{x}<br>Feature=%{y}<extra></extra>",
         "legendgroup": "Interaction",
         "marker": {
          "color": "#10B981",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Interaction",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": {
          "bdata": "W7Xd7U869T/OGZgUpmbyP1vFEKeAgvE/JLRwQT804T8xRywwKRDZPw==",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": [
          "peak_low_acuity",
          "weekend_low_acuity",
          "green_low_acuity",
          "elderly_ctas_2",
          "yellow_high_acuity"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Type=Patient<br>Importance=%{x}<br>Feature=%{y}<extra></extra>",
         "legendgroup": "Patient",
         "marker": {
          "color": "#3B82F6",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Patient",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": {
          "bdata": "tm3f9Acd9T+K+hRDriHxP6NzZEKq8fA/g9S5mAlE8D9ol9cD3UjsP/iREcsA0+U/5M50NOfr4z9Xu43ntIHjPw7d3HM4sN0/",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": [
          "age_scaled",
          "age_squared",
          "is_green_zone",
          "is_yellow_zone",
          "triage_code_clean",
          "is_low_acuity",
          "is_high_acuity_zone",
          "is_ambulance",
          "is_medium_acuity"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 500,
        "legend": {
         "title": {
          "text": "Type"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>Admission Model â€” Top Features</b>"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Importance"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryorder": "total ascending",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Feature"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient features: 37.1% of importance\n",
      "  Interaction features: 20.1% of importance\n",
      "  Operational features: 42.8% of importance\n",
      "\n",
      "LWBS MODEL:\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Type=Operational<br>Importance=%{x}<br>Feature=%{y}<extra></extra>",
         "legendgroup": "Operational",
         "marker": {
          "color": "#F59E0B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Operational",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": {
          "bdata": "XCJ42J5j3T83xxIin9TCP6qOIxjtLqk/V5y2cZPdkz+5UP3x7RuKP87dOH0CLYI/Ihdcs0PqeD/KLvkgyUNxPyVrLYrQZG0/HnyyC04jZj8=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": [
          "hist_lwbs_rate",
          "lwbs_risk_score",
          "admit_risk_score",
          "triage_lwbs_rate",
          "hour_admit_rate",
          "hist_admit_rate",
          "expected_wait_score",
          "hour_volume_scaled",
          "congestion_score",
          "hour_lwbs_rate"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Type=Patient<br>Importance=%{x}<br>Feature=%{y}<extra></extra>",
         "legendgroup": "Patient",
         "marker": {
          "color": "#3B82F6",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Patient",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": {
          "bdata": "1Oq+2Tzfsj9cYN7BzouwP7QuOGMnYLA/X0omEYEtnD8ppKSoElaNPypC7WrMmYY//Q6pEkPiej9p/LYoY4p3Pw==",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": [
          "day_num",
          "age_squared",
          "age_scaled",
          "is_male",
          "is_ambulance",
          "is_medium_acuity",
          "is_weekend",
          "hour_sin"
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "Type=Interaction<br>Importance=%{x}<br>Feature=%{y}<extra></extra>",
         "legendgroup": "Interaction",
         "marker": {
          "color": "#10B981",
          "pattern": {
           "shape": ""
          }
         },
         "name": "Interaction",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": {
          "bdata": "ZlAfxmR3hT+rppWcyW1qPw==",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": [
          "ambulance_high_acuity",
          "peak_low_acuity"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 500,
        "legend": {
         "title": {
          "text": "Type"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>LWBS Model â€” Top Features</b>"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Importance"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryorder": "total ascending",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Feature"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient features: 26.9% of importance\n",
      "  Interaction features: 1.5% of importance\n",
      "  Operational features: 71.6% of importance\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 19: FEATURE IMPORTANCE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def plot_feature_importance(model, feature_names, title, top_n=20):\n",
    "    \"\"\"Plot feature importance with operational vs patient feature breakdown.\"\"\"\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importance = model.feature_importances_\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        importance = np.abs(model.coef_[0])\n",
    "    else:\n",
    "        print(\"Model doesn't support feature importance\")\n",
    "        return None\n",
    "    \n",
    "    # Create dataframe\n",
    "    imp_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance\n",
    "    }).sort_values('Importance', ascending=False).head(top_n)\n",
    "    \n",
    "    # Mark feature types\n",
    "    imp_df['Type'] = imp_df['Feature'].apply(\n",
    "        lambda x: 'Operational' if x in OPERATIONAL_FEATURES else \n",
    "                  'Interaction' if x in INTERACTION_FEATURES else 'Patient'\n",
    "    )\n",
    "    \n",
    "    # Plot\n",
    "    colors = {'Patient': '#3B82F6', 'Interaction': '#10B981', 'Operational': '#F59E0B'}\n",
    "    \n",
    "    fig = px.bar(\n",
    "        imp_df,\n",
    "        x='Importance',\n",
    "        y='Feature',\n",
    "        color='Type',\n",
    "        color_discrete_map=colors,\n",
    "        orientation='h',\n",
    "        title=f'<b>{title}</b>'\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(height=500, yaxis={'categoryorder': 'total ascending'})\n",
    "    fig.show()\n",
    "    \n",
    "    # Calculate contribution by type\n",
    "    total_imp = importance.sum()\n",
    "    for ftype in ['Patient', 'Interaction', 'Operational']:\n",
    "        type_features = [f for f in feature_names if \n",
    "                        (f in OPERATIONAL_FEATURES and ftype == 'Operational') or\n",
    "                        (f in INTERACTION_FEATURES and ftype == 'Interaction') or\n",
    "                        (f not in OPERATIONAL_FEATURES + INTERACTION_FEATURES and ftype == 'Patient')]\n",
    "        type_imp = sum(importance[feature_names.index(f)] for f in type_features if f in feature_names)\n",
    "        print(f\"  {ftype} features: {type_imp/total_imp*100:.1f}% of importance\")\n",
    "    \n",
    "    return imp_df\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nADMISSION MODEL:\")\n",
    "imp_adm = plot_feature_importance(tuned_model_adm, ALL_FEATURES, \n",
    "                                   \"Admission Model â€” Top Features\")\n",
    "\n",
    "print(\"\\nLWBS MODEL:\")\n",
    "imp_lwbs = plot_feature_importance(tuned_model_lwbs, ALL_FEATURES,\n",
    "                                   \"LWBS Model â€” Top Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Operational Integration\n",
    "\n",
    "**How Triage Lead Uses Both Models Together**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Combined risk scoring functions defined\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 20: COMBINED RISK SCORING FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def predict_patient_risk(patient_features: dict, \n",
    "                         admission_model, admission_threshold,\n",
    "                         lwbs_model, lwbs_threshold,\n",
    "                         feature_list: list) -> dict:\n",
    "    \"\"\"\n",
    "    Generate combined risk assessment for a single patient.\n",
    "    \n",
    "    This is what runs at triage time for each patient.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to array\n",
    "    X = np.array([[patient_features.get(f, 0) for f in feature_list]])\n",
    "    \n",
    "    # Get predictions\n",
    "    adm_prob = admission_model.predict_proba(X)[0, 1]\n",
    "    lwbs_prob = lwbs_model.predict_proba(X)[0, 1]\n",
    "    \n",
    "    # Determine risk levels\n",
    "    adm_risk = 'HIGH' if adm_prob >= admission_threshold else \\\n",
    "               'MEDIUM' if adm_prob >= admission_threshold * 0.7 else 'LOW'\n",
    "    \n",
    "    lwbs_risk = 'HIGH' if lwbs_prob >= np.percentile([lwbs_prob], 95) else \\\n",
    "                'MEDIUM' if lwbs_prob >= np.percentile([lwbs_prob], 85) else 'LOW'\n",
    "    \n",
    "    # Combined priority score (for queue ordering)\n",
    "    priority_score = (adm_prob * 0.6) + (lwbs_prob * 0.4)\n",
    "    \n",
    "    return {\n",
    "        'admission_probability': adm_prob,\n",
    "        'admission_risk': adm_risk,\n",
    "        'lwbs_probability': lwbs_prob,\n",
    "        'lwbs_risk': lwbs_risk,\n",
    "        'priority_score': priority_score,\n",
    "        'recommended_actions': get_recommended_actions(adm_risk, lwbs_risk)\n",
    "    }\n",
    "\n",
    "def get_recommended_actions(adm_risk: str, lwbs_risk: str) -> list:\n",
    "    \"\"\"Generate actionable recommendations based on risk levels.\"\"\"\n",
    "    \n",
    "    actions = []\n",
    "    \n",
    "    if adm_risk == 'HIGH':\n",
    "        actions.append(\"ðŸ›ï¸ Start bed search / notify admitting\")\n",
    "        actions.append(\"ðŸ“ž Consider early consult request\")\n",
    "    elif adm_risk == 'MEDIUM':\n",
    "        actions.append(\"ðŸ‘ï¸ Monitor for admission indicators\")\n",
    "    \n",
    "    if lwbs_risk == 'HIGH':\n",
    "        actions.append(\"â° Check on patient after 20 min\")\n",
    "        actions.append(\"ðŸ’¬ Proactively communicate wait time\")\n",
    "    elif lwbs_risk == 'MEDIUM':\n",
    "        actions.append(\"ðŸ“‹ Add to LWBS watch list\")\n",
    "    \n",
    "    if not actions:\n",
    "        actions.append(\"âœ“ Standard care pathway\")\n",
    "    \n",
    "    return actions\n",
    "\n",
    "print(\"âœ“ Combined risk scoring functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SAMPLE PATIENT PREDICTIONS\n",
      "======================================================================\n",
      "\n",
      "Patient 0:\n",
      "  Age: 82, Triage: CTAS 3\n",
      "  Ambulance: Yes, Peak: Yes\n",
      "  Admission: ðŸ”´ HIGH (79.9%) | Actual: Admitted\n",
      "  LWBS Risk: 0.1% | Actual: Stayed\n",
      "\n",
      "Patient 100:\n",
      "  Age: 18, Triage: CTAS 3\n",
      "  Ambulance: No, Peak: Yes\n",
      "  Admission: ðŸŸ¢ LOW (18.2%) | Actual: Discharged\n",
      "  LWBS Risk: 1.2% | Actual: Stayed\n",
      "\n",
      "Patient 500:\n",
      "  Age: 58, Triage: CTAS 2\n",
      "  Ambulance: Yes, Peak: Yes\n",
      "  Admission: ðŸ”´ HIGH (82.4%) | Actual: Admitted\n",
      "  LWBS Risk: 0.2% | Actual: Stayed\n",
      "\n",
      "Patient 1000:\n",
      "  Age: 40, Triage: CTAS 3\n",
      "  Ambulance: No, Peak: No\n",
      "  Admission: ðŸŸ¡ MED (49.1%) | Actual: Admitted\n",
      "  LWBS Risk: 2.9% | Actual: Stayed\n",
      "\n",
      "Patient 1500:\n",
      "  Age: 45, Triage: CTAS 2\n",
      "  Ambulance: Yes, Peak: Yes\n",
      "  Admission: ðŸ”´ HIGH (90.6%) | Actual: Discharged\n",
      "  LWBS Risk: 0.2% | Actual: Stayed\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 21: DEMONSTRATION â€” SAMPLE PATIENT PREDICTIONS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SAMPLE PATIENT PREDICTIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get a few sample patients from test set\n",
    "sample_indices = [0, 100, 500, 1000, 1500]\n",
    "\n",
    "for idx in sample_indices:\n",
    "    if idx < len(X_test_adm):\n",
    "        patient = X_test_adm.iloc[idx]\n",
    "        actual_adm = y_test_adm.iloc[idx]\n",
    "        actual_lwbs = y_test_lwbs.iloc[idx] if idx < len(y_test_lwbs) else 'N/A'\n",
    "        \n",
    "        # Get predictions\n",
    "        adm_prob = tuned_model_adm.predict_proba(patient.values.reshape(1, -1))[0, 1]\n",
    "        lwbs_prob = tuned_model_lwbs.predict_proba(patient.values.reshape(1, -1))[0, 1]\n",
    "        \n",
    "        adm_flag = \"ðŸ”´ HIGH\" if adm_prob >= optimal_threshold_adm else \\\n",
    "                   \"ðŸŸ¡ MED\" if adm_prob >= optimal_threshold_adm * 0.7 else \"ðŸŸ¢ LOW\"\n",
    "        \n",
    "        print(f\"\\nPatient {idx}:\")\n",
    "        print(f\"  Age: {patient['age_scaled']*100:.0f}, Triage: CTAS {patient['triage_code_clean']:.0f}\")\n",
    "        print(f\"  Ambulance: {'Yes' if patient['is_ambulance'] else 'No'}, Peak: {'Yes' if patient['is_peak_hours'] else 'No'}\")\n",
    "        print(f\"  Admission: {adm_flag} ({adm_prob:.1%}) | Actual: {'Admitted' if actual_adm else 'Discharged'}\")\n",
    "        print(f\"  LWBS Risk: {lwbs_prob:.1%} | Actual: {'LWBS' if actual_lwbs == 1 else 'Stayed'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ“Š FINAL MODEL SUMMARY\n",
      "======================================================================\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚                       ADMISSION PREDICTION                              â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  Best Model:    Logistic Regression                                â”‚\n",
      "â”‚  AUC-ROC:       0.8495                                               â”‚\n",
      "â”‚  PR-AUC:        0.5117                                               â”‚\n",
      "â”‚  Precision:     0.4526 (45% of flags correct)                       â”‚\n",
      "â”‚  Recall:        0.6225 (62% of admissions caught)                    â”‚\n",
      "â”‚  Threshold:     0.676                                                â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚                        LWBS PREDICTION                                  â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚  Best Model:    Gradient Boosting                                  â”‚\n",
      "â”‚  AUC-ROC:       0.8531                                               â”‚\n",
      "â”‚  Top 5% Lift:   7.7x                                                  â”‚\n",
      "â”‚  Top 5% Capture:38% of LWBS cases                                   â”‚\n",
      "â”‚  Top 10% Capture:53% of LWBS cases                                  â”‚\n",
      "â”‚  Approach:      Risk tiers (not binary)                                 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ðŸ’¡ HOW TRIAGE LEAD USES BOTH MODELS\n",
      "======================================================================\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ AT TRIAGE:                                                              â”‚\n",
      "â”‚                                                                         â”‚\n",
      "â”‚   1. Patient data entered â†’ Both models run in parallel (<100ms)        â”‚\n",
      "â”‚                                                                         â”‚\n",
      "â”‚   2. Dashboard displays:                                                â”‚\n",
      "â”‚      â€¢ Admission Risk:  ðŸ”´ HIGH / ðŸŸ¡ MEDIUM / ðŸŸ¢ LOW                    â”‚\n",
      "â”‚      â€¢ LWBS Risk Tier:  TOP 5% / TOP 15% / STANDARD                     â”‚\n",
      "â”‚                                                                         â”‚\n",
      "â”‚   3. Triage Lead acts:                                                  â”‚\n",
      "â”‚      â€¢ HIGH Admission â†’ Start bed search, early consult                 â”‚\n",
      "â”‚      â€¢ TOP 5% LWBS â†’ Proactive check after 20 min                       â”‚\n",
      "â”‚      â€¢ Both risks â†’ Highest priority attention                          â”‚\n",
      "â”‚                                                                         â”‚\n",
      "â”‚ VALUE: Focus limited resources on highest-impact patients               â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 22: FINAL SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ“Š FINAL MODEL SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                       ADMISSION PREDICTION                              â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Best Model:    {best_model_name_adm:<50} â”‚\n",
    "â”‚  AUC-ROC:       {metrics_adm_final['auc']:.4f}                                               â”‚\n",
    "â”‚  PR-AUC:        {metrics_adm_final['pr_auc']:.4f}                                               â”‚\n",
    "â”‚  Precision:     {metrics_adm_final['precision']:.4f} ({metrics_adm_final['precision']*100:.0f}% of flags correct)                       â”‚\n",
    "â”‚  Recall:        {metrics_adm_final['recall']:.4f} ({metrics_adm_final['recall']*100:.0f}% of admissions caught)                    â”‚\n",
    "â”‚  Threshold:     {metrics_adm_final['threshold']:.3f}                                                â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                        LWBS PREDICTION                                  â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚  Best Model:    {best_model_name_lwbs:<50} â”‚\n",
    "â”‚  AUC-ROC:       {metrics_lwbs_final['auc']:.4f}                                               â”‚\n",
    "â”‚  Top 5% Lift:   {lwbs_lift_results[2]['lift']:.1f}x                                                  â”‚\n",
    "â”‚  Top 5% Capture:{lwbs_lift_results[2]['capture_rate']*100:.0f}% of LWBS cases                                   â”‚\n",
    "â”‚  Top 10% Capture:{lwbs_lift_results[3]['capture_rate']*100:.0f}% of LWBS cases                                  â”‚\n",
    "â”‚  Approach:      Risk tiers (not binary)                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ’¡ HOW TRIAGE LEAD USES BOTH MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ AT TRIAGE:                                                              â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚   1. Patient data entered â†’ Both models run in parallel (<100ms)        â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚   2. Dashboard displays:                                                â”‚\n",
    "â”‚      â€¢ Admission Risk:  ðŸ”´ HIGH / ðŸŸ¡ MEDIUM / ðŸŸ¢ LOW                    â”‚\n",
    "â”‚      â€¢ LWBS Risk Tier:  TOP 5% / TOP 15% / STANDARD                     â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚   3. Triage Lead acts:                                                  â”‚\n",
    "â”‚      â€¢ HIGH Admission â†’ Start bed search, early consult                 â”‚\n",
    "â”‚      â€¢ TOP 5% LWBS â†’ Proactive check after 20 min                       â”‚\n",
    "â”‚      â€¢ Both risks â†’ Highest priority attention                          â”‚\n",
    "â”‚                                                                         â”‚\n",
    "â”‚ VALUE: Focus limited resources on highest-impact patients               â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STRATEGIC RECOMMENDATION: SINGLE vs MULTI-TARGET\n",
      "======================================================================\n",
      "\n",
      "QUESTION: Should we optimize ONE target or MULTIPLE targets?\n",
      "\n",
      "ANSWER: BUILD TWO OPTIMIZED MODELS (Admission + LWBS)\n",
      "\n",
      "JUSTIFICATION:\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ Criterion       â”‚ Two Models Advantage                                    â”‚\n",
      "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
      "â”‚ Workflow Impact â”‚ Different actions: Admission â†’ beds, LWBS â†’ monitoring  â”‚\n",
      "â”‚ Decision Latencyâ”‚ Both run in parallel (<100ms total)                     â”‚\n",
      "â”‚ Interpretabilityâ”‚ Clear separation: \"admission risk\" vs \"LWBS risk\"       â”‚\n",
      "â”‚ Actionability   â”‚ Each triggers distinct, non-conflicting interventions   â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "WHY NOT SINGLE TARGET?\n",
      "\n",
      "â€¢ Admission-only: Misses LWBS risk entirely (different patients)\n",
      "â€¢ LWBS-only: Ignores bed planning (biggest operational need)\n",
      "â€¢ PIA-only: Weak predictive signal (RÂ²=0.15), limited actionability\n",
      "\n",
      "WHY NOT PIA?\n",
      "\n",
      "â€¢ RÂ² = 0.15 means 85% of variance unexplained\n",
      "â€¢ Cannot reliably communicate wait times to patients\n",
      "â€¢ Less actionable than admission/LWBS decisions\n",
      "\n",
      "TRADE-OFFS OF TWO-MODEL APPROACH:\n",
      "\n",
      "â€¢ +More complete risk picture\n",
      "â€¢ +Enables different interventions\n",
      "â€¢ -Slightly more complexity to deploy\n",
      "â€¢ -Two thresholds to calibrate\n",
      "\n",
      "CONCLUSION: The marginal complexity is worth the operational value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 23: ANSWER TO STRATEGIC QUESTION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"STRATEGIC RECOMMENDATION: SINGLE vs MULTI-TARGET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "QUESTION: Should we optimize ONE target or MULTIPLE targets?\n",
    "\n",
    "ANSWER: BUILD TWO OPTIMIZED MODELS (Admission + LWBS)\n",
    "\n",
    "JUSTIFICATION:\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Criterion       â”‚ Two Models Advantage                                    â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ Workflow Impact â”‚ Different actions: Admission â†’ beds, LWBS â†’ monitoring  â”‚\n",
    "â”‚ Decision Latencyâ”‚ Both run in parallel (<100ms total)                     â”‚\n",
    "â”‚ Interpretabilityâ”‚ Clear separation: \"admission risk\" vs \"LWBS risk\"       â”‚\n",
    "â”‚ Actionability   â”‚ Each triggers distinct, non-conflicting interventions   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "WHY NOT SINGLE TARGET?\n",
    "\n",
    "â€¢ Admission-only: Misses LWBS risk entirely (different patients)\n",
    "â€¢ LWBS-only: Ignores bed planning (biggest operational need)\n",
    "â€¢ PIA-only: Weak predictive signal (RÂ²=0.15), limited actionability\n",
    "\n",
    "WHY NOT PIA?\n",
    "\n",
    "â€¢ RÂ² = 0.15 means 85% of variance unexplained\n",
    "â€¢ Cannot reliably communicate wait times to patients\n",
    "â€¢ Less actionable than admission/LWBS decisions\n",
    "\n",
    "TRADE-OFFS OF TWO-MODEL APPROACH:\n",
    "\n",
    "â€¢ +More complete risk picture\n",
    "â€¢ +Enables different interventions\n",
    "â€¢ -Slightly more complexity to deploy\n",
    "â€¢ -Two thresholds to calibrate\n",
    "\n",
    "CONCLUSION: The marginal complexity is worth the operational value.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Models exported to FINAL_MODELS dictionary\n",
      "\n",
      "Usage:\n",
      "  admission_model = FINAL_MODELS['admission']['model']\n",
      "  threshold = FINAL_MODELS['admission']['threshold']\n",
      "  features = FINAL_MODELS['admission']['features']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 24: EXPORT MODELS FOR DASHBOARD\n",
    "# =============================================================================\n",
    "\n",
    "# Store final models and configuration\n",
    "FINAL_MODELS = {\n",
    "    'admission': {\n",
    "        'model': tuned_model_adm,\n",
    "        'threshold': optimal_threshold_adm,\n",
    "        'model_type': best_model_name_adm,\n",
    "        'features': ALL_FEATURES,\n",
    "        'metrics': metrics_adm_final\n",
    "    },\n",
    "    'lwbs': {\n",
    "        'model': tuned_model_lwbs,\n",
    "        'threshold': optimal_threshold_lwbs,\n",
    "        'model_type': best_model_name_lwbs,\n",
    "        'features': ALL_FEATURES,\n",
    "        'metrics': metrics_lwbs_final,\n",
    "        'lift_results': lwbs_lift_results\n",
    "    }\n",
    "}\n",
    "\n",
    "# Feature engineering function reference\n",
    "FEATURE_ENGINEERING_FN = engineer_features_production\n",
    "\n",
    "print(\"âœ“ Models exported to FINAL_MODELS dictionary\")\n",
    "print(\"\\nUsage:\")\n",
    "print(\"  admission_model = FINAL_MODELS['admission']['model']\")\n",
    "print(\"  threshold = FINAL_MODELS['admission']['threshold']\")\n",
    "print(\"  features = FINAL_MODELS['admission']['features']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODULE 5: MACHINE LEARNING â€” COMPLETE\n",
      "================================================================================\n",
      "\n",
      "WHAT WE BUILT:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "1. Comprehensive feature engineering (48 features)\n",
      "   â€¢ Patient demographics + triage assessment\n",
      "   â€¢ Temporal patterns + zone characteristics\n",
      "   â€¢ Operational context (historical patterns) â† KEY INNOVATION\n",
      "   â€¢ Domain-driven interaction features\n",
      "\n",
      "2. Rigorous model comparison (5 algorithms)\n",
      "   â€¢ Logistic Regression (baseline)\n",
      "   â€¢ Random Forest\n",
      "   â€¢ Gradient Boosting\n",
      "   â€¢ XGBoost (if available)\n",
      "   â€¢ LightGBM (if available)\n",
      "\n",
      "3. Hyperparameter tuning (RandomizedSearchCV)\n",
      "   â€¢ 5-fold stratified cross-validation\n",
      "   â€¢ 40 parameter combinations tested\n",
      "\n",
      "4. Threshold optimization\n",
      "   â€¢ Admission: Balanced precision/recall\n",
      "   â€¢ LWBS: Lift-based tiers (not binary)\n",
      "\n",
      "5. Production-ready outputs\n",
      "   â€¢ FINAL_MODELS dictionary with all artifacts\n",
      "   â€¢ Feature engineering function\n",
      "   â€¢ Combined risk scoring for dashboard\n",
      "\n",
      "KEY RESULTS:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "â€¢ Admission: AUC ~0.85, Precision ~50%, Recall ~57%\n",
      "â€¢ LWBS: AUC ~0.86, Top 5% captures ~40% of LWBS (8x lift)\n",
      "â€¢ Both models run in parallel for complete risk picture\n",
      "\n",
      "RECOMMENDATION:\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Deploy BOTH models as complementary decision support tools.\n",
      "They serve different purposes and trigger different actions.\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 25: MODULE SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\"\"\n",
    "================================================================================\n",
    "MODULE 5: MACHINE LEARNING â€” COMPLETE\n",
    "================================================================================\n",
    "\n",
    "WHAT WE BUILT:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "1. Comprehensive feature engineering (48 features)\n",
    "   â€¢ Patient demographics + triage assessment\n",
    "   â€¢ Temporal patterns + zone characteristics\n",
    "   â€¢ Operational context (historical patterns) â† KEY INNOVATION\n",
    "   â€¢ Domain-driven interaction features\n",
    "\n",
    "2. Rigorous model comparison (5 algorithms)\n",
    "   â€¢ Logistic Regression (baseline)\n",
    "   â€¢ Random Forest\n",
    "   â€¢ Gradient Boosting\n",
    "   â€¢ XGBoost (if available)\n",
    "   â€¢ LightGBM (if available)\n",
    "\n",
    "3. Hyperparameter tuning (RandomizedSearchCV)\n",
    "   â€¢ 5-fold stratified cross-validation\n",
    "   â€¢ 40 parameter combinations tested\n",
    "\n",
    "4. Threshold optimization\n",
    "   â€¢ Admission: Balanced precision/recall\n",
    "   â€¢ LWBS: Lift-based tiers (not binary)\n",
    "\n",
    "5. Production-ready outputs\n",
    "   â€¢ FINAL_MODELS dictionary with all artifacts\n",
    "   â€¢ Feature engineering function\n",
    "   â€¢ Combined risk scoring for dashboard\n",
    "\n",
    "KEY RESULTS:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "â€¢ Admission: AUC ~0.85, Precision ~50%, Recall ~57%\n",
    "â€¢ LWBS: AUC ~0.86, Top 5% captures ~40% of LWBS (8x lift)\n",
    "â€¢ Both models run in parallel for complete risk picture\n",
    "\n",
    "RECOMMENDATION:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Deploy BOTH models as complementary decision support tools.\n",
    "They serve different purposes and trigger different actions.\n",
    "================================================================================\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
